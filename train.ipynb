{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Flight Delay Prediction - XGBoost Model Training\n",
                "\n",
                "This notebook trains an XGBoost regressor to predict flight delays and exports the model for production use."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from xgboost import XGBRegressor\n",
                "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
                "import pickle\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set plotting style\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "\n",
                "print(\"✓ All libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load and Explore Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the dataset\n",
                "df = pd.read_csv('synth_data/data/flight_delays.csv')\n",
                "\n",
                "print(f\"Dataset Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display column information\n",
                "print(\"Column Names and Types:\")\n",
                "print(\"=\"*80)\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistical summary\n",
                "print(\"Dataset Statistics:\")\n",
                "print(\"=\"*80)\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for missing values\n",
                "print(\"Missing Values:\")\n",
                "print(\"=\"*80)\n",
                "missing = df.isnull().sum()\n",
                "missing[missing > 0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make a copy for processing\n",
                "df_processed = df.copy()\n",
                "\n",
                "# Identify target variable (delay_minutes or similar)\n",
                "target_col = None\n",
                "for col in df.columns:\n",
                "    if 'delay' in col.lower() and 'minute' in col.lower():\n",
                "        target_col = col\n",
                "        break\n",
                "\n",
                "if target_col is None:\n",
                "    # Try to find any column with 'delay' in name\n",
                "    for col in df.columns:\n",
                "        if 'delay' in col.lower():\n",
                "            target_col = col\n",
                "            break\n",
                "\n",
                "if target_col is None:\n",
                "    print(\"ERROR: Could not find target column with 'delay' in name.\")\n",
                "    print(\"Available columns:\", df.columns.tolist())\n",
                "    print(\"\\nPlease specify the target column name manually.\")\n",
                "else:\n",
                "    print(f\"✓ Target Variable Identified: {target_col}\")\n",
                "    \n",
                "    # Separate features and target\n",
                "    y = df_processed[target_col]\n",
                "    X = df_processed.drop(columns=[target_col])\n",
                "    \n",
                "    print(f\"✓ Features: {X.shape[1]} columns\")\n",
                "    print(f\"✓ Target: {target_col} (mean: {y.mean():.2f}, std: {y.std():.2f})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handle missing values\n",
                "print(\"Handling missing values...\")\n",
                "\n",
                "# For numerical columns, fill with median\n",
                "numerical_cols = X.select_dtypes(include=[np.number]).columns\n",
                "for col in numerical_cols:\n",
                "    if X[col].isnull().sum() > 0:\n",
                "        X[col].fillna(X[col].median(), inplace=True)\n",
                "        print(f\"  ✓ Filled {col} with median\")\n",
                "\n",
                "# For categorical columns, fill with mode\n",
                "categorical_cols = X.select_dtypes(include=['object']).columns\n",
                "for col in categorical_cols:\n",
                "    if X[col].isnull().sum() > 0:\n",
                "        X[col].fillna(X[col].mode()[0], inplace=True)\n",
                "        print(f\"  ✓ Filled {col} with mode\")\n",
                "\n",
                "print(f\"\\n✓ Missing values handled!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Encode categorical variables\n",
                "print(f\"Encoding {len(categorical_cols)} categorical columns...\")\n",
                "\n",
                "label_encoders = {}\n",
                "for col in categorical_cols:\n",
                "    le = LabelEncoder()\n",
                "    X[col] = le.fit_transform(X[col].astype(str))\n",
                "    label_encoders[col] = le\n",
                "    print(f\"  ✓ Encoded {col}\")\n",
                "\n",
                "print(f\"\\n✓ Final feature set: {X.shape[1]} columns\")\n",
                "print(\"\\nFeature columns:\", X.columns.tolist())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train-Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split the data\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42\n",
                ")\n",
                "\n",
                "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
                "print(f\"Testing set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
                "\n",
                "# Feature scaling (using StandardScaler)\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(\"\\n✓ Data split and scaled successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Training (XGBoost)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Training XGBoost Model...\")\n",
                "# Using X_train_scaled to match the scaler that will be saved\n",
                "model = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
                "model.fit(X_train_scaled, y_train)\n",
                "\n",
                "y_pred = model.predict(X_test_scaled)\n",
                "\n",
                "# Calculate metrics\n",
                "r2 = r2_score(y_test, y_pred)\n",
                "mae = mean_absolute_error(y_test, y_pred)\n",
                "mse = mean_squared_error(y_test, y_pred)\n",
                "rmse = np.sqrt(mse)\n",
                "\n",
                "print(f\"\\n✓ XGBoost Results:\")\n",
                "print(f\"  R² Score: {r2:.4f}\")\n",
                "print(f\"  MAE: {mae:.4f}\")\n",
                "print(f\"  RMSE: {rmse:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "plt.scatter(y_test, y_pred, alpha=0.5, s=10)\n",
                "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
                "plt.xlabel('Actual Delay (minutes)')\n",
                "plt.ylabel('Predicted Delay (minutes)')\n",
                "plt.title(f'Actual vs Predicted - XGBoost (R²: {r2:.4f})', fontsize=14, fontweight='bold')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.savefig('xgboost_actual_vs_predicted.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"✓ Visualization saved to: xgboost_actual_vs_predicted.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Model and Scaler"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the XGBoost model and artifacts\n",
                "model_filename = 'xgboost_flight_delay_model.pkl'\n",
                "\n",
                "with open(model_filename, 'wb') as f:\n",
                "    pickle.dump({\n",
                "        'model': model,\n",
                "        'scaler': scaler,\n",
                "        'label_encoders': label_encoders,\n",
                "        'feature_names': X.columns.tolist(),\n",
                "        'model_name': 'XGBoost',\n",
                "        'r2_score': r2,\n",
                "        'rmse': rmse\n",
                "    }, f)\n",
                "\n",
                "print(f\"✓ Model and Scaler saved to: {model_filename}\")\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"TRAINING COMPLETE!\")\n",
                "print(\"=\"*80)\n",
                "print(f\"\\nSaved artifacts include:\")\n",
                "print(\"- XGBRegressor Model\")\n",
                "print(\"- StandardScaler\")\n",
                "print(\"- LabelEncoders\")\n",
                "print(\"- Feature Names\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}